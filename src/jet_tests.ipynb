{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jetnet\n",
    "from jetnet.datasets import JetNet\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gen_metrics\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "import pickle\n",
    "import plotting\n",
    "from typing import OrderedDict\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 16})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "plot_dir = \"../plots/jet_plots/Feb3\"\n",
    "_ = os.system(f\"mkdir -p {plot_dir}\")\n",
    "\n",
    "data_dir = \"../saved_data/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_jets_pf, _ = JetNet.getData(\n",
    "    \"g\",\n",
    "    data_dir=\"/Users/raghav/Documents/CERN/gen-models/MPGAN/datasets/\",\n",
    "    split_fraction=[1.0, 0, 0],\n",
    "    particle_features=[\"etarel\", \"phirel\", \"ptrel\"],\n",
    "    jet_features=[\"pt\", \"eta\", \"mass\", \"num_particles\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efps = jetnet.utils.efps(truth_jets_pf[:, :, :3], efpset_args=[(\"d<=\", 4)])\n",
    "# np.save(\"efps\", efps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efps_true = np.load(f\"{data_dir}/efps_true.npy\")\n",
    "pnet_activations_true = np.load(f\"{data_dir}/pnet_activations_true.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.lookup_tools.dense_lookup import dense_lookup\n",
    "\n",
    "mass = jetnet.utils.jet_features(truth_jets_pf[:, :, :3])[\"mass\"]\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "bins = np.linspace(0, np.max(mass), 26)\n",
    "true_mass_hist = np.histogram(mass, bins)[0]\n",
    "\n",
    "smeared_hist = np.histogram(mass * np.random.normal(1, 0.25, size=mass.shape), bins)[0]\n",
    "shifted_hist = np.histogram(mass * np.random.normal(1.1, 0.05, size=mass.shape), bins)[0]\n",
    "\n",
    "smeared_lookup = dense_lookup(smeared_hist / true_mass_hist, bins)\n",
    "shifted_lookup = dense_lookup(shifted_hist / true_mass_hist, bins)\n",
    "\n",
    "smeared_weights = smeared_lookup(mass)\n",
    "smeared_weights /= np.sum(smeared_weights)\n",
    "\n",
    "shifted_weights = shifted_lookup(mass)\n",
    "shifted_weights /= np.sum(shifted_weights)\n",
    "\n",
    "tailcut_weights = (mass < 0.17).astype(float)\n",
    "tailcut_weights /= np.sum(tailcut_weights)\n",
    "\n",
    "dists = OrderedDict(\n",
    "    [\n",
    "        (\"truth\", (np.ones(truth_jets_pf.shape[0]) / truth_jets_pf.shape[0], \"Truth\")),\n",
    "        (\"smeared\", (smeared_weights, \"Smeared\")),\n",
    "        (\"shifted\", (shifted_weights, \"Shifted\")),\n",
    "        (\"tailcut\", (tailcut_weights, \"Removing tail\")),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(4)\n",
    "\n",
    "# pf_dists = OrderedDict()\n",
    "\n",
    "# pf_dists[\"all_smeared\"] = (\n",
    "#     truth_jets_pf * np.random.normal(1, 0.25, size=truth_jets_pf.shape),\n",
    "#     \"Particle Features Smeared\",\n",
    "# )\n",
    "# pf_dists[\"eta_smeared\"] = (\n",
    "#     np.concatenate(\n",
    "#         (\n",
    "#             truth_jets_pf[..., 0:1] * np.random.normal(1, 0.25, size=truth_jets_pf[..., 0:1].shape),\n",
    "#             truth_jets_pf[..., 1:],\n",
    "#         ),\n",
    "#         axis=-1,\n",
    "#     ),\n",
    "#     r\"Particle $\\eta^{rel}$ Smeared\",\n",
    "# )\n",
    "# pf_dists[\"pt_smeared\"] = (\n",
    "#     np.concatenate(\n",
    "#         (\n",
    "#             truth_jets_pf[..., :2],\n",
    "#             truth_jets_pf[..., 2:3] * np.random.normal(1, 0.25, size=truth_jets_pf[..., 2:3].shape),\n",
    "#         ),\n",
    "#         axis=-1,\n",
    "#     ),\n",
    "#     r\"Particle $p_T^{rel}$ Smeared\",\n",
    "# )\n",
    "# pf_dists[\"pt_shifted\"] = (\n",
    "#     np.concatenate(\n",
    "#         (\n",
    "#             truth_jets_pf[..., :2],\n",
    "#             truth_jets_pf[..., 2:3]\n",
    "#             * np.random.normal(0.9, 0.1, size=truth_jets_pf[..., 2:3].shape),\n",
    "#         ),\n",
    "#         axis=-1,\n",
    "#     ),\n",
    "#     r\"Particle $p_T^{rel}$ Shifted\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pf_dists.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(pf_dists, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efps = {\n",
    "#     key: jetnet.utils.efps(jets, efpset_args=[(\"d<=\", 4)]) for key, (jets, _) in pf_dists.items()\n",
    "# }\n",
    "#\n",
    "# with open(\"efps_dict.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(efps, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{data_dir}/pf_dists.pkl\", \"rb\") as f:\n",
    "    pf_dists = pickle.load(f)\n",
    "\n",
    "with open(f\"{data_dir}/efps_dict.pkl\", \"rb\") as f:\n",
    "    efps = pickle.load(f)\n",
    "\n",
    "pnet_activations = {}\n",
    "\n",
    "for key in pf_dists:\n",
    "    pnet_activations[key] = np.load(f\"{data_dir}/pnet_activations_{key}.npy\")\n",
    "\n",
    "masses = {key: jetnet.utils.jet_features(jets)[\"mass\"] for key, (jets, _) in pf_dists.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_dists[\"all_smeared\"] = (pf_dists[\"all_smeared\"][0], \"Particle features smeared\")\n",
    "pf_dists[\"pt_smeared\"] = (pf_dists[\"pt_smeared\"][0], r\"Particle $p_T^{rel}$ smeared\")\n",
    "pf_dists[\"pt_shifted\"] = (pf_dists[\"pt_shifted\"][0], r\"Particle $p_T^{rel}$ shifted\")\n",
    "pf_dists[\"eta_smeared\"] = (pf_dists[\"eta_smeared\"][0], r\"Particle $\\eta^{rel}$ smeared\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(3).repeat(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smeared_weights.repeat(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(\n",
    "    font_scale=2,\n",
    "    rc={\n",
    "        \"axes.axisbelow\": False,\n",
    "        \"axes.edgecolor\": \"#141E27\",\n",
    "        \"axes.facecolor\": \"None\",\n",
    "        \"axes.grid\": False,\n",
    "        \"axes.labelcolor\": \"#141E27\",\n",
    "        # \"axes.spines.right\": False,\n",
    "        # \"axes.spines.top\": False,\n",
    "        \"figure.facecolor\": \"white\",\n",
    "        \"lines.solid_capstyle\": \"round\",\n",
    "        \"patch.edgecolor\": \"w\",\n",
    "        \"patch.force_edgecolor\": True,\n",
    "        \"text.color\": \"#141E27\",\n",
    "        \"xtick.bottom\": False,\n",
    "        \"xtick.color\": \"dimgrey\",\n",
    "        \"xtick.direction\": \"out\",\n",
    "        \"xtick.top\": False,\n",
    "        \"ytick.color\": \"dimgrey\",\n",
    "        \"ytick.direction\": \"out\",\n",
    "        \"ytick.left\": False,\n",
    "        \"ytick.right\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "# # colours = [\"#3F88C5\", \"#B3541E\", \"#990000\", \"#D00000\", \"#FF5B00\", \"#7CB518\", \"#064635\", \"#142F43\"]\n",
    "\n",
    "\n",
    "def plot_dists(true_feat_dist, pf_feat_dists, bins, feat_label, name, log = False, pf = False):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "\n",
    "    colours = [\"#3F88C5\", \"#990000\", \"#7CB518\", \"#FF5B00\", \"#142F43\"]\n",
    "\n",
    "    for ax in axes:\n",
    "        _ = ax.hist(\n",
    "            true_feat_dist if not pf else true_feat_dist.reshape(-1), bins, histtype=\"step\", label=\"Truth\", linewidth=4, density=True, color=colours[0]\n",
    "        )\n",
    "    \n",
    "    for i, (weights, label) in enumerate(dists.values()):\n",
    "        if label == \"Truth\":\n",
    "            continue\n",
    "\n",
    "        _ = axes[0].hist(\n",
    "            true_feat_dist if not pf else true_feat_dist.reshape(-1),\n",
    "            bins,\n",
    "            weights=weights if not pf else weights.repeat(30),\n",
    "            histtype=\"step\",\n",
    "            label=label,\n",
    "            linewidth=2,\n",
    "            linestyle=\"dashed\",\n",
    "            density=True,\n",
    "            color=colours[i],\n",
    "        )\n",
    "\n",
    "    for i, (key, (_, label)) in enumerate(pf_dists.items()):\n",
    "        _ = axes[1].hist(\n",
    "            pf_feat_dists[key] if not pf else pf_feat_dists[key].reshape(-1),\n",
    "            bins,\n",
    "            histtype=\"step\",\n",
    "            label=label,\n",
    "            linewidth=2,\n",
    "            linestyle=\"dashed\",\n",
    "            density=True,\n",
    "            color=colours[i + 1],\n",
    "        )\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.margins(x=0)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(feat_label)\n",
    "        ax.set_ylabel(\"Probability (A.U.)\")\n",
    "\n",
    "        if log:\n",
    "            ax.set_yscale('log')\n",
    "\n",
    "    plt.savefig(f\"{plot_dir}/jet_{name}_dists.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efp_index = 25\n",
    "efp_index2 = 12\n",
    "\n",
    "plot_params = [\n",
    "    # [mass, masses, np.linspace(0, 0.22, 101), r\"Jet $m/p_T$\", \"mass\"],\n",
    "    # [efps_true[:, efp_index2], {key: efps[key][:, efp_index2] for key in efps}, np.linspace(0, 0.004, 101), r\"Sample d = 3 EFP\", f\"efp{efp_index2}\", True],\n",
    "    # [efps_true[:, efp_index], {key: efps[key][:, efp_index] for key in efps}, np.linspace(0, 0.0004, 101), r\"Sample d = 4 EFP\", \"efp25\"],\n",
    "    [truth_jets_pf[:, :, 0], {key: pf_dists[key][0][:, :, 0] for key in efps}, np.linspace(-0.2, 0.2, 101), r\"Particle $\\eta^{rel}$\", \"parteta\", False, True],\n",
    "    [truth_jets_pf[:, :, 2], {key: pf_dists[key][0][:, :, 2] for key in efps}, np.linspace(0, 0.15, 101), r\"Particle $p_T^{rel}$\", \"partpt\", False, True],\n",
    "]\n",
    "\n",
    "for params in plot_params:\n",
    "    plot_dists(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "bins = np.linspace(0, 0.01, 101)\n",
    "# bins = np.linspace(0, 0.25, 101)\n",
    "efp_index = 25\n",
    "\n",
    "_ = plt.hist(\n",
    "    efps_true[:, efp_index], bins, histtype=\"step\", label=\"Truth\", linewidth=3, density=True\n",
    ")\n",
    "for weights, label in dists.values():\n",
    "    if label == \"Truth\":\n",
    "        continue\n",
    "\n",
    "    _ = plt.hist(\n",
    "        efps_true[:, efp_index],\n",
    "        bins,\n",
    "        weights=weights,\n",
    "        histtype=\"step\",\n",
    "        label=label,\n",
    "        linewidth=2,\n",
    "        linestyle=\"dashed\",\n",
    "        density=True,\n",
    "    )\n",
    "for key, (_, label) in pf_dists.items():\n",
    "    _ = plt.hist(\n",
    "        efps[key][:, efp_index],\n",
    "        bins,\n",
    "        histtype=\"step\",\n",
    "        label=label,\n",
    "        linewidth=2,\n",
    "        linestyle=\"dashed\",\n",
    "        density=True,\n",
    "    )\n",
    "plt.legend()\n",
    "plt.xlabel(r\"Jet $m/p_T$\")\n",
    "plt.ylabel(\"Normalized # of Jets\")\n",
    "plt.yscale('log')\n",
    "plt.savefig(f\"{plot_dir}/jet_dists_efp.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 150_000\n",
    "sample_efps = OrderedDict()\n",
    "sample_acts = OrderedDict()\n",
    "sample_masses = OrderedDict()\n",
    "\n",
    "np.random.seed(4)\n",
    "true_inds = np.random.choice(np.arange(truth_jets_pf.shape[0]), num_samples)\n",
    "true_mass = mass[true_inds]\n",
    "true_efps = efps_true[true_inds]\n",
    "true_acts = pnet_activations_true[true_inds]\n",
    "\n",
    "for key, (weights, _) in dists.items():\n",
    "    inds = np.random.choice(np.arange(truth_jets_pf.shape[0]), num_samples, p=weights)\n",
    "    sample_masses[key] = mass[inds]\n",
    "    sample_efps[key] = efps_true[inds]\n",
    "    sample_acts[key] = pnet_activations_true[inds]\n",
    "    # np.save(f\"../distorted_jets/{key}.npy\", truth_jets_pf[inds])\n",
    "\n",
    "for key in pf_dists:\n",
    "    inds = np.random.choice(np.arange(truth_jets_pf.shape[0]), num_samples)\n",
    "    sample_masses[key] = masses[key][inds]\n",
    "    sample_efps[key] = efps[key][inds]\n",
    "    sample_acts[key] = pnet_activations[key][inds]\n",
    "    # np.save(f\"../distorted_jets/{key}.npy\", pf_dists[key][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"{data_dir}/sample_efps.pkl\", 'wb') as f:\n",
    "#     pickle.dump(sample_efps, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 5\n",
    "\n",
    "batch_sizes = {\n",
    "    \"w1m\": [\n",
    "        100,\n",
    "        200,\n",
    "        300,\n",
    "        500,\n",
    "        750,\n",
    "        1000,\n",
    "        1500,\n",
    "        2000,\n",
    "        3000,\n",
    "        5000,\n",
    "        7500,\n",
    "        10000,\n",
    "        15000,\n",
    "        20000,\n",
    "        25000,\n",
    "        30000,\n",
    "        40000,\n",
    "        50000,\n",
    "    ],\n",
    "    \"wasserstein\": [100, 200, 300, 500, 750, 1000, 1500, 2000],\n",
    "    \"fgd\": [\n",
    "        100,\n",
    "        200,\n",
    "        300,\n",
    "        500,\n",
    "        750,\n",
    "        1000,\n",
    "        1500,\n",
    "        2000,\n",
    "        3000,\n",
    "        5000,\n",
    "        7500,\n",
    "        10000,\n",
    "        15000,\n",
    "        20000,\n",
    "        25000,\n",
    "        30000,\n",
    "        40000,\n",
    "        50000,\n",
    "    ],\n",
    "    \"fgd_inf\": [25_000, 30_000, 40_000, 50_000],\n",
    "    \"mmdup4\": [100, 200, 300, 500, 750, 1000, 1500, 2000, 3000, 4000, 5000],\n",
    "    \"pr\": [100, 200, 300, 500, 750, 1000, 1500, 2000, 3000, 4000, 5000],\n",
    "}\n",
    "\n",
    "metrics = OrderedDict(\n",
    "    [\n",
    "        (\"wasserstein\", (gen_metrics.wasserstein, {\"normalise\": False}, \"Wasserstein\")),\n",
    "        (\"fgd\", (gen_metrics.frechet_gaussian_distance, {}, \"Fréchet Gaussian Distance\")),\n",
    "        (\"fgd_inf\", (gen_metrics.frechet_gaussian_distance, {}, r\"$\\mathrm{FGD}_{\\infty}$\")),\n",
    "        (\n",
    "            \"mmdup4\",\n",
    "            (\n",
    "                gen_metrics.mmd_poly_quadratic_unbiased,\n",
    "                {\"degree\": 4},\n",
    "                \"MMD\",\n",
    "            ),\n",
    "        ),\n",
    "        (\"pr\", (gen_metrics.pr, {}, [\"Precision\", \"Recall\"])),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_dir = \"../plots/jet_plots/Nov11\"\n",
    "\n",
    "with open(f\"{measurements_dir}/measurements_w1m.pkl\", \"rb\") as f:\n",
    "    measurements_w1m = pickle.load(f)\n",
    "\n",
    "with open(f\"{measurements_dir}/measurements_efps.pkl\", \"rb\") as f:\n",
    "    measurements_efps = pickle.load(f)\n",
    "\n",
    "with open(f\"{measurements_dir}/measurements_acts.pkl\", \"rb\") as f:\n",
    "    measurements_acts = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_w1m = OrderedDict()\n",
    "mkey = \"w1m\"\n",
    "\n",
    "for dkey in sample_masses:\n",
    "    ms = []\n",
    "    ts = []\n",
    "    for batch_size in tqdm(batch_sizes[mkey], desc=mkey):\n",
    "        mean_std, timing = gen_metrics.multi_batch_evaluation(\n",
    "            true_mass,\n",
    "            sample_masses[dkey],\n",
    "            num_batches,\n",
    "            batch_size,\n",
    "            gen_metrics.wasserstein1d,\n",
    "            timing=True,\n",
    "            normalise=False,\n",
    "        )\n",
    "        ms.append(mean_std)\n",
    "        ts.append(timing)\n",
    "\n",
    "    measurements_w1m[dkey] = {\"mean_std\": np.array(ms), \"timing\": np.array(ts)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"measurements_efps\" not in locals():\n",
    "    measurements_efps = OrderedDict()\n",
    "\n",
    "for dkey in sample_efps:\n",
    "    print(dkey)\n",
    "    if dkey not in measurements_efps:\n",
    "        measurements_efps[dkey] = OrderedDict()\n",
    "\n",
    "    for mkey, (metric, metric_args, label) in metrics.items():\n",
    "        if (mkey in measurements_efps[dkey] or mkey == \"fgd_inf\") and not mkey == \"mmdup4\":\n",
    "            continue\n",
    "\n",
    "        ms = []\n",
    "        ts = []\n",
    "\n",
    "        # ms = list(measurements_efps[dkey][mkey][\"mean_std\"])\n",
    "        # ts = list(measurements_efps[dkey][mkey][\"timing\"])\n",
    "\n",
    "        for batch_size in tqdm(batch_sizes[mkey][len(ms) :], desc=mkey):\n",
    "            # mean_std, timing = gen_metrics.multi_batch_evaluation(\n",
    "            #     true_efps,\n",
    "            #     sample_efps[dkey],\n",
    "            #     num_batches,\n",
    "            #     batch_size,\n",
    "            #     metric,\n",
    "            #     timing=True,\n",
    "            #     **metric_args\n",
    "            # )\n",
    "            # ms.append(mean_std)\n",
    "            # ts.append(timing)\n",
    "\n",
    "            mean_std = gen_metrics.multi_batch_evaluation_mmd(\n",
    "                true_efps,\n",
    "                sample_efps[dkey],\n",
    "                num_batches,\n",
    "                batch_size,\n",
    "            )\n",
    "            ms.append(mean_std)\n",
    "            ts.append(0)\n",
    "\n",
    "        measurements_efps[dkey][mkey] = {\"mean_std\": np.array(ms), \"timing\": np.array(ts)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FGD Infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkey = \"fgd_inf\"\n",
    "\n",
    "for dkey in sample_efps:\n",
    "    ms = []\n",
    "    ts = []\n",
    "    for n in tqdm(batch_sizes[mkey], desc=dkey):\n",
    "        mean_std, timing = gen_metrics.one_over_n_extrapolation_repeated_measurements(true_efps, sample_efps[dkey], normalise=True, max_samples=n, timing=True)\n",
    "        ms.append(mean_std)\n",
    "        ts.append(timing)\n",
    "\n",
    "    measurements_efps[dkey][mkey] = {\"mean_std\": np.array(ms), \"timing\": np.array(ts)}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParticleNet Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"measurements_acts\" not in locals():\n",
    "    measurements_acts = OrderedDict()\n",
    "\n",
    "for dkey in sample_acts:\n",
    "    print(dkey)\n",
    "    if dkey not in measurements_acts:\n",
    "        measurements_acts[dkey] = OrderedDict()\n",
    "\n",
    "    for mkey, (metric, metric_args, label) in metrics.items():\n",
    "        if (mkey in measurements_acts[dkey] or mkey == \"fgd_inf\") and not mkey == \"mmdup4\":\n",
    "            continue\n",
    "\n",
    "        ms = []\n",
    "        ts = []\n",
    "\n",
    "        # ms = list(measurements_acts[dkey][mkey][\"mean_std\"])[:-2]\n",
    "        # ts = list(measurements_acts[dkey][mkey][\"timing\"])[:-2]\n",
    "\n",
    "        for batch_size in tqdm(batch_sizes[mkey][len(ms) :], desc=mkey):\n",
    "            # mean_std, timing = gen_metrics.multi_batch_evaluation(\n",
    "            #     true_acts,\n",
    "            #     sample_acts[dkey],\n",
    "            #     num_batches,\n",
    "            #     batch_size,\n",
    "            #     metric,\n",
    "            #     timing=True,\n",
    "            #     **metric_args,\n",
    "            #     normalise=False\n",
    "            # )\n",
    "            # ms.append(mean_std)\n",
    "            # ts.append(timing)\n",
    "\n",
    "            mean_std = gen_metrics.multi_batch_evaluation_mmd(\n",
    "                true_acts,\n",
    "                sample_acts[dkey],\n",
    "                num_batches,\n",
    "                batch_size,\n",
    "                normalise=False,\n",
    "            )\n",
    "            ms.append(mean_std)\n",
    "            ts.append(0)\n",
    "\n",
    "        measurements_acts[dkey][mkey] = {\"mean_std\": np.array(ms), \"timing\": np.array(ts)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FGD Infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkey = \"fgd_inf\"\n",
    "\n",
    "for dkey in sample_acts:\n",
    "    ms = []\n",
    "    ts = []\n",
    "    for n in tqdm(batch_sizes[mkey], desc=dkey):\n",
    "        mean_std, timing = gen_metrics.one_over_n_extrapolation_repeated_measurements(true_acts, sample_acts[dkey], normalise=True, max_samples=n, timing=True)\n",
    "        ms.append(mean_std)\n",
    "        ts.append(timing)\n",
    "\n",
    "    measurements_acts[dkey][mkey] = {\"mean_std\": np.array(ms), \"timing\": np.array(ts)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{plot_dir}/measurements_w1m.pkl\", \"wb\") as f:\n",
    "    pickle.dump(measurements_w1m, f)\n",
    "\n",
    "with open(f\"{plot_dir}/measurements_efps.pkl\", \"wb\") as f:\n",
    "    pickle.dump(measurements_efps, f)\n",
    "\n",
    "with open(f\"{plot_dir}/measurements_acts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(measurements_acts, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vals in measurements_acts.values():\n",
    "#     vals[\"mmdup4\"]['mean_std'][:, 1] /= 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 24})\n",
    "matplotlib.rc_file_defaults()\n",
    "\n",
    "ylims = OrderedDict(\n",
    "    [\n",
    "        (\n",
    "            \"w1m\",\n",
    "            (\n",
    "                [0, 0.04],\n",
    "                [0, 0.05],\n",
    "                [0, 0.06],\n",
    "                [0, 0.05],\n",
    "                [0, 0.05],\n",
    "                [0, 0.05],\n",
    "                [0, 0.05],\n",
    "                [0, 0.05],\n",
    "            ),\n",
    "        ),\n",
    "        (\"wasserstein\", ([0, 0.25], [0, 1], [0, 1], [0, 0.5], [0, 2], [0, 1], [0, 1], [0, 0.5])),\n",
    "        # (\n",
    "        #     \"fgd\",\n",
    "        #     ([0, 0.25], [0, 0.5], [0, 1], [0, 0.1], [0, 0.25], [0, 0.25], [0, 0.15], [0, 0.25]),\n",
    "        # ),\n",
    "        (\n",
    "            \"fgd_inf\",\n",
    "            (\n",
    "                [0, 0.0002],\n",
    "                [0, 0.1],\n",
    "                [0, 0.1],\n",
    "                [0, 0.01],\n",
    "                [0, 0.05],\n",
    "                [-0.01, 0.01],\n",
    "                [-0.01, 0.01],\n",
    "                [-0.1, 0.1],\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"mmdup4\",\n",
    "            (\n",
    "                [-0.0002, 0.0002],\n",
    "                [-0.001, 0.001],\n",
    "                [-0.001, 0.003],\n",
    "                [-0.0002, 0.0002],\n",
    "                [-0.001, 0.001],\n",
    "                [-0.0002, 0.0002],\n",
    "                [-0.0002, 0.0002],\n",
    "                [0, 0.005],\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"precision\",\n",
    "            ([0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1]),\n",
    "        ),\n",
    "        (\n",
    "            \"recall\",\n",
    "            ([0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1]),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(ylims),\n",
    "    ncols=len(dists | pf_dists),\n",
    "    figsize=(len(dists | pf_dists) * 10, len(ylims) * 8),\n",
    "    gridspec_kw={\"wspace\": 0.25},\n",
    ")\n",
    "\n",
    "i = 0\n",
    "mkey = \"w1m\"\n",
    "plotting.metric_label(axes[i][0], r\"$W_1^M$\")\n",
    "for j, (dkey, (_, label)) in enumerate((dists | pf_dists).items()):\n",
    "    axes[i][j].set_title(label)\n",
    "    plotting.plot_means_stds(\n",
    "        axes[i][j], measurements_w1m[dkey][\"mean_std\"], batch_sizes[mkey], ylims[mkey][j]\n",
    "    )\n",
    "\n",
    "for (mkey, (metric, metric_args, label)) in metrics.items():\n",
    "    if mkey in [\"dc\", \"pr\"] or mkey not in ylims:\n",
    "        continue\n",
    "\n",
    "    i = list(ylims.keys()).index(mkey)\n",
    "\n",
    "    plotting.metric_label(axes[i][0], label)\n",
    "    for j, (dkey, (_, label)) in enumerate((dists | pf_dists).items()):\n",
    "        if i == 0:\n",
    "            axes[i][j].set_title(label)\n",
    "\n",
    "        plotting.plot_means_stds(\n",
    "            axes[i][j], measurements_efps[dkey][mkey][\"mean_std\"], batch_sizes[mkey], ylims[mkey][j]\n",
    "        )\n",
    "\n",
    "for k, key in enumerate([\"precision\", \"recall\"]):\n",
    "    i = len(ylims) - 2 + k\n",
    "    mkey = \"pr\"\n",
    "\n",
    "    plotting.metric_label(axes[i][0], metrics[mkey][2][k])\n",
    "    for j, dkey in enumerate(dists | pf_dists):\n",
    "        plotting.plot_means_stds(\n",
    "            axes[i][j],\n",
    "            measurements_efps[dkey][mkey][\"mean_std\"][:, :, k],\n",
    "            batch_sizes[mkey],\n",
    "            ylims[key][j],\n",
    "        )\n",
    "\n",
    "\n",
    "plt.savefig(f\"{plot_dir}/efps_scores.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "ylims = OrderedDict(\n",
    "    [\n",
    "        (\"wasserstein\", ([0, 10], [0, 10], [0, 10], [0, 10], [0, 15], [0, 10], [0, 15], [0, 25])),\n",
    "        # (\"fgd\", ([0, 2], [0, 2], [0, 2], [0, 2], [0, 5], [0, 2], [0, 8], [0, 10])),\n",
    "        (\n",
    "            \"fgd_inf\",\n",
    "            ([0, 0.01], [0, 0.25], [0, 1], [-0.02, 0.02], [0, 4], [-0.01, 0.2], [0, 4], [0, 8]),\n",
    "        ),\n",
    "        (\n",
    "            \"mmdup4\",\n",
    "            (\n",
    "                [-0.02, 0.02],\n",
    "                [-0.1, 0.1],\n",
    "                [-0.2, 0.2],\n",
    "                [-0.1, 0.1],\n",
    "                [0, 1],\n",
    "                [-0.1, 0.1],\n",
    "                [0, 1],\n",
    "                [0, 2],\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"precision\",\n",
    "            ([0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1]),\n",
    "        ),\n",
    "        (\n",
    "            \"recall\",\n",
    "            ([0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1], [0, 1.1]),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(ylims),\n",
    "    ncols=len(dists | pf_dists),\n",
    "    figsize=(len(dists | pf_dists) * 10, len(ylims) * 8),\n",
    "    gridspec_kw={\"wspace\": 0.25},\n",
    ")\n",
    "\n",
    "for (mkey, (metric, metric_args, label)) in metrics.items():\n",
    "    if mkey in [\"dc\", \"pr\"] or mkey not in ylims:\n",
    "        continue\n",
    "\n",
    "    i = list(ylims.keys()).index(mkey)\n",
    "\n",
    "    plotting.metric_label(axes[i][0], label)\n",
    "    for j, (dkey, (_, label)) in enumerate((dists | pf_dists).items()):\n",
    "        if i == 0:\n",
    "            axes[i][j].set_title(label)\n",
    "\n",
    "        plotting.plot_means_stds(\n",
    "            axes[i][j], measurements_acts[dkey][mkey][\"mean_std\"], batch_sizes[mkey], ylims[mkey][j]\n",
    "        )\n",
    "\n",
    "for k, key in enumerate([\"precision\", \"recall\"]):\n",
    "    i = len(ylims) - 2 + k\n",
    "    mkey = \"pr\"\n",
    "\n",
    "    plotting.metric_label(axes[i][0], metrics[mkey][2][k])\n",
    "    for j, dkey in enumerate(dists | pf_dists):\n",
    "        plotting.plot_means_stds(\n",
    "            axes[i][j],\n",
    "            measurements_acts[dkey][mkey][\"mean_std\"][:, :, k],\n",
    "            batch_sizes[mkey],\n",
    "            ylims[key][j],\n",
    "        )\n",
    "\n",
    "plt.savefig(f\"{plot_dir}/acts_scores.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_mean_std(mean_stds: np.ndarray):\n",
    "    mean, sd = mean_stds\n",
    "    sd = np.abs(sd)\n",
    "\n",
    "    if sd == 0:\n",
    "        return f\"${mean:.1f} \\\\pm 0.0$\"\n",
    "\n",
    "    \"\"\"round mean and standard deviation to most significant digit of sd and apply latex formatting\"\"\"\n",
    "    decimals = -int(np.floor(np.log10(sd)))\n",
    "    decimals -= int((sd * 10**decimals) >= 9.5)\n",
    "    decimals = min(decimals, 3)\n",
    "\n",
    "    if decimals < 0:\n",
    "        ten_to = 10 ** (-decimals)\n",
    "        if mean > ten_to:\n",
    "            mean = ten_to * (mean // ten_to)\n",
    "        else:\n",
    "            mean_ten_to = 10 ** np.floor(np.log10(mean))\n",
    "            mean = mean_ten_to * (mean // mean_ten_to)\n",
    "        sd = ten_to * (sd // ten_to)\n",
    "        decimals = 0\n",
    "\n",
    "    if mean >= 1e3 and sd >= 1e3:\n",
    "        mean = np.round(mean * 1e-3)\n",
    "        sd = np.round(sd * 1e-3)\n",
    "        return f\"${mean:.{decimals}f}$k $\\\\pm {sd:.{decimals}f}$k\"\n",
    "    else:\n",
    "        return f\"${mean:.{decimals}f} \\\\pm {sd:.{decimals}f}$\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean_std(mean_stds: np.ndarray):\n",
    "    return f\"{mean_stds[0]:.3f} ± {mean_stds[1]:.3f}\"\n",
    "\n",
    "\n",
    "rows = []\n",
    "sigs = []  # keeping track of significances\n",
    "\n",
    "row = [r\"$W_1^M \\times 10^3$\"]\n",
    "sigrow = [\"\\quad\\quad Sign.\", \"---\"]\n",
    "sig = []\n",
    "true_mean, true_std = measurements_w1m[\"truth\"][\"mean_std\"][-1]\n",
    "for dkey, values in measurements_w1m.items():\n",
    "    row.append(format_mean_std(values[\"mean_std\"][-1, :] * 1e3))\n",
    "\n",
    "    sigv = (values[\"mean_std\"][-1, 0] - true_mean) / true_std\n",
    "    sigerr = values[\"mean_std\"][-1, 1] * sigv / values[\"mean_std\"][-1, 0]\n",
    "    sig.append(sigv)\n",
    "\n",
    "    if dkey != \"truth\":\n",
    "        sigrow.append(format_mean_std([sigv, sigerr]) if sigv > 0 else \"0\")\n",
    "\n",
    "rows.append(row)\n",
    "rows.append(sigrow)\n",
    "sigs.append(sig)\n",
    "\n",
    "\n",
    "for mkey, (metric, metric_args, label) in metrics.items():\n",
    "    if mkey == \"fgd\":\n",
    "        continue\n",
    "\n",
    "    if isinstance(label, list):\n",
    "        for i, l in enumerate(label):\n",
    "            row = [l + \" EFP\"]\n",
    "            sigrow = [\"\\quad\\quad Sign.\", \"---\"]\n",
    "            sig = []\n",
    "\n",
    "            true_mean, true_std = measurements_efps[\"truth\"][mkey][\"mean_std\"][-1, :, i]\n",
    "            for dkey, values in measurements_efps.items():\n",
    "                row.append(format_mean_std(values[mkey][\"mean_std\"][-1, :, i]))\n",
    "                sigv = -(values[mkey][\"mean_std\"][-1, 0, i] - true_mean) / true_std\n",
    "                sigerr = values[mkey][\"mean_std\"][-1, 1, i] * sigv / values[mkey][\"mean_std\"][-1, 0, i]\n",
    "                sig.append(sigv)\n",
    "\n",
    "                if dkey != \"truth\":\n",
    "                    sigrow.append(format_mean_std([sigv, sigerr]) if sigv > 0 else \"0\")\n",
    "\n",
    "            rows.append(row)\n",
    "            rows.append(sigrow)\n",
    "            sigs.append(sig)\n",
    "        # continue\n",
    "    else:\n",
    "        sigrow = [\"\\quad\\quad Sign.\", \"---\"]\n",
    "        sig = []\n",
    "        true_mean, true_std = measurements_efps[\"truth\"][mkey][\"mean_std\"][-1]\n",
    "\n",
    "        if mkey in [\"fgd_inf\", \"mmdup4\"]:\n",
    "            row = [f\"{label} EFP $\\\\times 10^3$\"]\n",
    "\n",
    "            for dkey, values in measurements_efps.items():\n",
    "                row.append(format_mean_std(values[mkey][\"mean_std\"][-1, :] * 1e3))\n",
    "                sigv = (values[mkey][\"mean_std\"][-1, 0] - true_mean) / true_std\n",
    "                sigerr = values[mkey][\"mean_std\"][-1, 1] * sigv / values[mkey][\"mean_std\"][-1, 0]\n",
    "                sig.append(sigv)\n",
    "\n",
    "                if dkey != \"truth\":\n",
    "                    sigrow.append(format_mean_std([sigv, sigerr]) if sigv > 0 else \"0\")\n",
    "\n",
    "        else:\n",
    "            row = [label + \" EFP\"]\n",
    "\n",
    "            for dkey, values in measurements_efps.items():\n",
    "                row.append(format_mean_std(values[mkey][\"mean_std\"][-1, :]))\n",
    "                sigv = (values[mkey][\"mean_std\"][-1, 0] - true_mean) / true_std\n",
    "                sigerr = values[mkey][\"mean_std\"][-1, 1] * sigv / values[mkey][\"mean_std\"][-1, 0]\n",
    "                sig.append(sigv)\n",
    "\n",
    "                if dkey != \"truth\":\n",
    "                    sigrow.append(format_mean_std([sigv, sigerr]) if sigv > 0 else \"0\")\n",
    "\n",
    "        rows.append(row)\n",
    "        rows.append(sigrow)\n",
    "        sigs.append(sig)\n",
    "\n",
    "for mkey, (metric, metric_args, label) in metrics.items():\n",
    "    if mkey == \"fgd\":\n",
    "        continue\n",
    "\n",
    "    if isinstance(label, list):\n",
    "        for i, l in enumerate(label):\n",
    "            row = [l + \" PN\"]\n",
    "            sigrow = [\"\\quad\\quad Sign.\", \"---\"]\n",
    "            sig = []\n",
    "\n",
    "            true_mean, true_std = measurements_acts[\"truth\"][mkey][\"mean_std\"][-1, :, i]\n",
    "\n",
    "            for dkey, values in measurements_acts.items():\n",
    "                row.append(format_mean_std(values[mkey][\"mean_std\"][-1, :, i]))\n",
    "                sigv = -(values[mkey][\"mean_std\"][-1, 0, i] - true_mean) / true_std\n",
    "                sigerr = values[mkey][\"mean_std\"][-1, 1, i] * sigv / values[mkey][\"mean_std\"][-1, 0, i]\n",
    "                sig.append(sigv)\n",
    "\n",
    "                if dkey != \"truth\":\n",
    "                    sigrow.append(format_mean_std([sigv, sigerr]) if sigv > 0 else \"0\")\n",
    "\n",
    "            rows.append(row)\n",
    "            rows.append(sigrow)\n",
    "            sigs.append(sig)\n",
    "    else:\n",
    "        sigrow = [\"\\quad\\quad Sign.\", \"---\"]\n",
    "        sig = []\n",
    "        true_mean, true_std = measurements_acts[\"truth\"][mkey][\"mean_std\"][-1]\n",
    "\n",
    "        if mkey in [\"fgd_inf\", \"mmdup4\"]:\n",
    "            row = [f\"{label} PN $\\\\times 10^3$\"]\n",
    "\n",
    "            for dkey, values in measurements_acts.items():\n",
    "                row.append(format_mean_std(values[mkey][\"mean_std\"][-1, :] * 1e3))\n",
    "                sigv = (values[mkey][\"mean_std\"][-1, 0] - true_mean) / true_std\n",
    "                sigerr = values[mkey][\"mean_std\"][-1, 1] * sigv / values[mkey][\"mean_std\"][-1, 0]\n",
    "                sig.append(sigv)\n",
    "\n",
    "                if dkey != \"truth\":\n",
    "                    sigrow.append(format_mean_std([sigv, sigerr]) if sigv > 0 else \"0\")\n",
    "\n",
    "        else:\n",
    "            row = [label + \" PN\"]\n",
    "\n",
    "            for dkey, values in measurements_acts.items():\n",
    "                row.append(format_mean_std(values[mkey][\"mean_std\"][-1, :]))\n",
    "                sigv = (values[mkey][\"mean_std\"][-1, 0] - true_mean) / true_std\n",
    "                sigerr = values[mkey][\"mean_std\"][-1, 1] * sigv / values[mkey][\"mean_std\"][-1, 0]\n",
    "                sig.append(sigv)\n",
    "\n",
    "                if dkey != \"truth\":\n",
    "                    sigrow.append(format_mean_std([sigv, sigerr]) if sigv > 0 else \"0\")\n",
    "\n",
    "        rows.append(row)\n",
    "        rows.append(sigrow)\n",
    "        sigs.append(sig)\n",
    "\n",
    "# https://graphgan.nrp-nautilus.io/hep-generative-metrics/classifier_trainings/\n",
    "pnet_aucs = [\n",
    "    0.5009051928,\n",
    "    0.5245543864000001,\n",
    "    0.5431707766,\n",
    "    0.5030471778,\n",
    "    0.9721441670000002,\n",
    "    0.8120980804,\n",
    "    0.934389781,\n",
    "    0.9887714117999998,\n",
    "]\n",
    "rows.append([\"Classifier LLF AUC\"] + [f\"{auc:.2f}\" for auc in pnet_aucs])\n",
    "\n",
    "hlf_aucs = [\n",
    "    0.5022573634,\n",
    "    0.5290901156,\n",
    "    0.5455009230000001,\n",
    "    0.5046839426,\n",
    "    0.8391819958,\n",
    "    0.6390696834,\n",
    "    0.7389946514000001,\n",
    "    0.9174882015999999,\n",
    "]\n",
    "rows.append([\"Classifier HLF AUC\"] + [f\"{auc:.2f}\" for auc in hlf_aucs])\n",
    "\n",
    "sigs = np.array(sigs)\n",
    "max_sigs = np.argmax(sigs, axis=0)\n",
    "\n",
    "for i, midx in enumerate(max_sigs[1:]):\n",
    "    rows[midx * 2][i + 2] = r\"$\\mathbf{\" + rows[midx * 2][i + 2][1:-1] + r\"}$\"\n",
    "    rows[midx * 2 + 1][i + 2] = r\"$\\mathbf{\" + rows[midx * 2 + 1][i + 2][1:-1] + r\"}$\"\n",
    "\n",
    "\n",
    "textable = [\n",
    "    \" & \".join([\"Metric\"] + list(np.array(list((dists | pf_dists).values()), dtype=object)[:, 1]))\n",
    "    + \"\\\\\\\\\\n\"\n",
    "] + [\" & \".join(row) + \"\\\\\\\\\\n\" for row in rows]\n",
    "\n",
    "for i in range(2, len(textable) - 2, 2):\n",
    "    textable[i] = textable[i][:-1] + \" \\midrule \\n\"\n",
    "\n",
    "textable[-1] = textable[-1][:-3]\n",
    "\n",
    "with open(f\"{plot_dir}/measurements.tex\", \"w\") as f:\n",
    "    f.writelines(textable)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    rows, columns=[\"Metric\"] + list(np.array(list((dists | pf_dists).values()), dtype=object)[:, 1])\n",
    ")\n",
    "\n",
    "display(Markdown(results.to_markdown()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('python310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31a7b1cb5f073f7a7d37b3db504c6954ce2b88e0f82e412b65ad0b5f2dd17394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
